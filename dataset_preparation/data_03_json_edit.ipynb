{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Number of GPUs: 1\n",
      "GPU name: NVIDIA A100-SXM4-40GB\n",
      "PyTorch version: 2.5.1+cu121\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "# Setting up the environment to use only GPU 2\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Check number of GPUs\n",
    "print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "\n",
    "# Check GPU name\n",
    "print(f\"GPU name: {torch.cuda.get_device_name()}\")\n",
    "\n",
    "# Check PyTorch version\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Dec  3 14:40:44 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.154.05             Driver Version: 535.154.05   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A100-SXM4-40GB          On  | 00000000:07:00.0 Off |                    0 |\n",
      "| N/A   36C    P0             230W / 400W |  11590MiB / 40960MiB |     98%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100-SXM4-40GB          On  | 00000000:0F:00.0 Off |                    0 |\n",
      "| N/A   47C    P0             260W / 400W |  27945MiB / 40960MiB |     97%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA A100-SXM4-40GB          On  | 00000000:47:00.0 Off |                    0 |\n",
      "| N/A   23C    P0              59W / 400W |   4950MiB / 40960MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA A100-SXM4-40GB          On  | 00000000:4E:00.0 Off |                    0 |\n",
      "| N/A   22C    P0              53W / 400W |    579MiB / 40960MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA A100-SXM4-40GB          On  | 00000000:87:00.0 Off |                    0 |\n",
      "| N/A   59C    P0             182W / 400W |   6802MiB / 40960MiB |     57%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA A100-SXM4-40GB          On  | 00000000:90:00.0 Off |                    0 |\n",
      "| N/A   45C    P0             176W / 400W |  18086MiB / 40960MiB |     51%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   6  NVIDIA A100-SXM4-40GB          On  | 00000000:B7:00.0 Off |                    0 |\n",
      "| N/A   26C    P0              55W / 400W |    291MiB / 40960MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   7  NVIDIA A100-SXM4-40GB          On  | 00000000:BD:00.0 Off |                    0 |\n",
      "| N/A   25C    P0              59W / 400W |   2334MiB / 40960MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A   3284776      C   ...uel/anaconda3/envs/ai231/bin/python     3960MiB |\n",
      "|    0   N/A  N/A   3290673      C   ...uel/anaconda3/envs/ai231/bin/python     6890MiB |\n",
      "|    1   N/A  N/A   3058948      C   python                                    16088MiB |\n",
      "|    1   N/A  N/A   3290674      C   ...uel/anaconda3/envs/ai231/bin/python     6886MiB |\n",
      "|    4   N/A  N/A   4190240      C   ...naconda3/envs/ai231-venv/bin/python     6778MiB |\n",
      "|    5   N/A  N/A   2274682      C   ...conda3/envs/bertram_mex5/bin/python    12000MiB |\n",
      "|    5   N/A  N/A   3068533      C   ...conda3/envs/bertram_mex5/bin/python     6004MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjust bounding boxes and segmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_coco_annotations(coco_json_path):\n",
    "    with open(coco_json_path, 'r') as f:\n",
    "        coco_data = json.load(f)\n",
    "    return coco_data\n",
    "\n",
    "def adjust_segmentations(annotations, image_width, image_height):\n",
    "    for annotation in annotations:\n",
    "        if 'segmentation' in annotation:\n",
    "            segmentation = annotation['segmentation']\n",
    "            for segment in segmentation:\n",
    "                for i in range(0, len(segment), 2):\n",
    "                    segment[i] = max(0, min(segment[i], image_width))\n",
    "                    segment[i + 1] = max(0, min(segment[i + 1], image_height))\n",
    "    return annotations\n",
    "\n",
    "def adjust_bounding_boxes(annotations, image_width, image_height):\n",
    "    for annotation in annotations:\n",
    "        bbox = annotation['bbox']\n",
    "        x, y, w, h = bbox\n",
    "        \n",
    "        # Ensure x and y are within the image boundaries\n",
    "        x = max(0, x)\n",
    "        y = max(0, y)\n",
    "        \n",
    "        # Adjust width and height to ensure the bounding box is within the image boundaries\n",
    "        if x + w > image_width:\n",
    "            w = image_width - x\n",
    "        if y + h > image_height:\n",
    "            h = image_height - y\n",
    "        \n",
    "        # Ensure bounding box does not extend beyond segmentation boundaries\n",
    "        if 'segmentation' in annotation:\n",
    "            segmentation = annotation['segmentation']\n",
    "            all_x = [segment[i] for segment in segmentation for i in range(0, len(segment), 2)]\n",
    "            all_y = [segment[i + 1] for segment in segmentation for i in range(0, len(segment), 2)]\n",
    "            min_x, max_x = min(all_x), max(all_x)\n",
    "            min_y, max_y = min(all_y), max(all_y)\n",
    "            \n",
    "            x = max(x, min_x)\n",
    "            y = max(y, min_y)\n",
    "            w = min(w, max_x - x)\n",
    "            h = min(h, max_y - y)\n",
    "        \n",
    "        annotation['bbox'] = [x, y, w, h]\n",
    "    return annotations\n",
    "\n",
    "def ensure_annotations_within_boundaries(coco_data):\n",
    "    images = {image['id']: (image['width'], image['height']) for image in coco_data['images']}\n",
    "    for annotation in coco_data['annotations']:\n",
    "        image_id = annotation['image_id']\n",
    "        image_width, image_height = images[image_id]\n",
    "        annotation = adjust_segmentations([annotation], image_width, image_height)[0]\n",
    "        annotation = adjust_bounding_boxes([annotation], image_width, image_height)[0]\n",
    "    return coco_data\n",
    "\n",
    "def save_coco_annotations(coco_data, output_path):\n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump(coco_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load COCO annotations\n",
    "coco_json_path = \"/data/students/mary/mlops-exercises/ME6/dataset__v3/adj_instances_train.json\"\n",
    "coco_data = load_coco_annotations(coco_json_path)\n",
    "\n",
    "# Ensure annotations are within image boundaries\n",
    "coco_data = ensure_annotations_within_boundaries(coco_data)\n",
    "\n",
    "# Save the adjusted COCO annotations\n",
    "output_coco_json_path = \"/data/students/mary/mlops-exercises/ME6/dataset__v3/adj01_instances_train.json\"\n",
    "save_coco_annotations(coco_data, output_coco_json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load COCO annotations\n",
    "coco_json_path = \"/data/students/mary/mlops-exercises/ME6/dataset__v3/adj_instances_val.json\"\n",
    "coco_data = load_coco_annotations(coco_json_path)\n",
    "\n",
    "# Ensure annotations are within image boundaries\n",
    "coco_data = ensure_annotations_within_boundaries(coco_data)\n",
    "\n",
    "# Save the adjusted COCO annotations\n",
    "output_coco_json_path = \"/data/students/mary/mlops-exercises/ME6/dataset__v3/adj01_instances_val.json\"\n",
    "save_coco_annotations(coco_data, output_coco_json_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Match V1 and V3 Category Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_v1 = \"/data/students/mary/mlops-exercises/ME6/dataset__v3/v1_instances_train.json\"\n",
    "file_v3 = \"/data/students/mary/mlops-exercises/ME6/dataset__v3/adj01_instances_train.json\"\n",
    "\n",
    "# Load the second JSON file\n",
    "with open(file_v1, 'r') as f1:\n",
    "    v1_data = json.load(f1)\n",
    "\n",
    "# Load the first JSON file\n",
    "with open(file_v3, 'r') as f3:\n",
    "    v3_data = json.load(f3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V1 Data\n",
      "ID: 1, Category: Coke Zero Bottled\n",
      "ID: 2, Category: Eden Cheese\n",
      "ID: 3, Category: KitKat\n",
      "ID: 4, Category: Nescafe 3-in-1 Twin Pack\n",
      "ID: 5, Category: Alaska Classic 377g Can\n",
      "ID: 6, Category: Simply Pure Canola Oil\n",
      "ID: 7, Category: Purefoods Corned Beef\n",
      "ID: 8, Category: Whole Bulb of Garlic\n",
      "ID: 9, Category: Lucky Me Pansit Canton\n",
      "ID: 10, Category: UFC Banana Ketchup\n",
      "ID: 11, Category: Whole Lemon\n",
      "ID: 12, Category: Nestle All Purpose Cream 250ml\n",
      "ID: 13, Category: Lady's Choice Real Mayonnaise 220 ml jar\n",
      "ID: 14, Category: Skippy Peanut Butter\n",
      "ID: 15, Category: Royal Pasta\n",
      "ID: 16, Category: Del Monte Pineapple Juice\n",
      "ID: 17, Category: Rebisco Crackers\n",
      "ID: 18, Category: 555 Sardines\n",
      "ID: 19, Category: Sunsilk Shampoo\n",
      "ID: 20, Category: Dove Lavender Soap\n",
      "ID: 21, Category: Silver Swan Soy Sauce - 385 mL\n",
      "ID: 22, Category: Colgate (Advanced White) Value Pack (2 Tubes)\n",
      "ID: 23, Category: Century Tuna\n",
      "ID: 24, Category: GreenCross Alcohol\n",
      "\n",
      "V3 Data\n",
      "ID: 1, Category: Coke Zero Bottled\n",
      "ID: 2, Category: Eden Cheese\n",
      "ID: 3, Category: KitKat\n",
      "ID: 4, Category: Nescafe 3-in-1 Twin Pack\n",
      "ID: 5, Category: Alaska Classic 377g Can\n",
      "ID: 6, Category: Simply Pure Canola Oil\n",
      "ID: 7, Category: Purefoods Corned Beef\n",
      "ID: 8, Category: Whole Bulb of Garlic\n",
      "ID: 9, Category: Lucky Me Pansit Canton\n",
      "ID: 10, Category: UFC Banana Ketchup\n",
      "ID: 11, Category: Whole Lemon\n",
      "ID: 12, Category: Nestle All Purpose Cream 250ml\n",
      "ID: 13, Category: Lady's Choice Real Mayonnaise 220 ml jar\n",
      "ID: 14, Category: Skippy Peanut Butter\n",
      "ID: 15, Category: Royal Pasta\n",
      "ID: 16, Category: Del Monte Pineapple Juice\n",
      "ID: 17, Category: Rebisco Crackers\n",
      "ID: 18, Category: 555 Sardines\n",
      "ID: 19, Category: Sunsilk Shampoo\n",
      "ID: 20, Category: Dove Lavender Soap\n",
      "ID: 21, Category: Silver Swan Soy Sauce - 385 mL\n",
      "ID: 22, Category: Colgate (Advanced White) Value Pack (2 Tubes)\n",
      "ID: 23, Category: Century Tuna\n",
      "ID: 24, Category: GreenCross Alcohol\n"
     ]
    }
   ],
   "source": [
    "v1_categories = v1_data['categories']\n",
    "\n",
    "# Sort categories by id\n",
    "sorted_categories = sorted(v1_categories, key=lambda x: x['id'])\n",
    "\n",
    "# Print sorted categories\n",
    "print(\"V1 Data\")\n",
    "for category in sorted_categories:\n",
    "    print(f\"ID: {category['id']}, Category: {category['name']}\")\n",
    "\n",
    "v3_categories = v3_data['categories']\n",
    "\n",
    "# Sort categories by id\n",
    "sorted_categories = sorted(v3_categories, key=lambda x: x['id'])\n",
    "\n",
    "# Print sorted categories\n",
    "print(\"\\nV3 Data\")\n",
    "for category in sorted_categories:\n",
    "    print(f\"ID: {category['id']}, Category: {category['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update Category Names\n",
    "for v1_category in v1_data['categories']:\n",
    "    for v3_category in v3_data['categories']:\n",
    "        if v1_category['id'] == v3_category['id']:\n",
    "            v1_category['name'] = v3_category['name']\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump the updated data to a file\n",
    "filename = f'/data/students/mary/mlops-exercises/ME6/dataset/json_files/v1_instances_train.json'\n",
    "with open(filename, 'w') as file:\n",
    "    json.dump(v1_data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_v1 = \"/data/students/mary/mlops-exercises/ME6/dataset__v3/v1_instances_val.json\"\n",
    "file_v3 = \"/data/students/mary/mlops-exercises/ME6/dataset__v3/adj01_instances_val.json\"\n",
    "\n",
    "# Load the second JSON file\n",
    "with open(file_v1, 'r') as f1:\n",
    "    v1_data = json.load(f1)\n",
    "\n",
    "# Load the first JSON file\n",
    "with open(file_v3, 'r') as f3:\n",
    "    v3_data = json.load(f3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V1 Data\n",
      "ID: 1, Category: Coke Zero Bottled\n",
      "ID: 2, Category: Eden Cheese\n",
      "ID: 3, Category: KitKat\n",
      "ID: 4, Category: Nescafe 3-in-1 Twin Pack\n",
      "ID: 5, Category: Alaska Classic 377g Can\n",
      "ID: 6, Category: Simply Pure Canola Oil\n",
      "ID: 7, Category: Purefoods Corned Beef\n",
      "ID: 8, Category: Whole Bulb of Garlic\n",
      "ID: 9, Category: Lucky Me Pansit Canton\n",
      "ID: 10, Category: UFC Banana Ketchup\n",
      "ID: 11, Category: Whole Lemon\n",
      "ID: 12, Category: Nestle All Purpose Cream 250ml\n",
      "ID: 13, Category: Lady's Choice Real Mayonnaise 220 ml jar\n",
      "ID: 14, Category: Skippy Peanut Butter\n",
      "ID: 15, Category: Royal Pasta\n",
      "ID: 16, Category: Del Monte Pineapple Juice\n",
      "ID: 17, Category: Rebisco Crackers\n",
      "ID: 18, Category: 555 Sardines\n",
      "ID: 19, Category: Sunsilk Shampoo\n",
      "ID: 20, Category: Dove Lavender Soap\n",
      "ID: 21, Category: Silver Swan Soy Sauce - 385 mL\n",
      "ID: 22, Category: Colgate (Advanced White) Value Pack (2 Tubes)\n",
      "ID: 23, Category: Century Tuna\n",
      "ID: 24, Category: GreenCross Alcohol\n",
      "\n",
      "V3 Data\n",
      "ID: 1, Category: Coke Zero Bottled\n",
      "ID: 2, Category: Eden Cheese\n",
      "ID: 3, Category: KitKat\n",
      "ID: 4, Category: Nescafe 3-in-1 Twin Pack\n",
      "ID: 5, Category: Alaska Classic 377g Can\n",
      "ID: 6, Category: Simply Pure Canola Oil\n",
      "ID: 7, Category: Purefoods Corned Beef\n",
      "ID: 8, Category: Whole Bulb of Garlic\n",
      "ID: 9, Category: Lucky Me Pansit Canton\n",
      "ID: 10, Category: UFC Banana Ketchup\n",
      "ID: 11, Category: Whole Lemon\n",
      "ID: 12, Category: Nestle All Purpose Cream 250ml\n",
      "ID: 13, Category: Lady's Choice Real Mayonnaise 220 ml jar\n",
      "ID: 14, Category: Skippy Peanut Butter\n",
      "ID: 15, Category: Royal Pasta\n",
      "ID: 16, Category: Del Monte Pineapple Juice\n",
      "ID: 17, Category: Rebisco Crackers\n",
      "ID: 18, Category: 555 Sardines\n",
      "ID: 19, Category: Sunsilk Shampoo\n",
      "ID: 20, Category: Dove Lavender Soap\n",
      "ID: 21, Category: Silver Swan Soy Sauce - 385 mL\n",
      "ID: 22, Category: Colgate (Advanced White) Value Pack (2 Tubes)\n",
      "ID: 23, Category: Century Tuna\n",
      "ID: 24, Category: GreenCross Alcohol\n"
     ]
    }
   ],
   "source": [
    "v1_categories = v1_data['categories']\n",
    "\n",
    "# Sort categories by id\n",
    "sorted_categories = sorted(v1_categories, key=lambda x: x['id'])\n",
    "\n",
    "# Print sorted categories\n",
    "print(\"V1 Data\")\n",
    "for category in sorted_categories:\n",
    "    print(f\"ID: {category['id']}, Category: {category['name']}\")\n",
    "\n",
    "v3_categories = v3_data['categories']\n",
    "\n",
    "# Sort categories by id\n",
    "sorted_categories = sorted(v3_categories, key=lambda x: x['id'])\n",
    "\n",
    "# Print sorted categories\n",
    "print(\"\\nV3 Data\")\n",
    "for category in sorted_categories:\n",
    "    print(f\"ID: {category['id']}, Category: {category['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update Category Names\n",
    "for v1_category in v1_data['categories']:\n",
    "    for v3_category in v3_data['categories']:\n",
    "        if v1_category['id'] == v3_category['id']:\n",
    "            v1_category['name'] = v3_category['name']\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump the updated data to a file\n",
    "filename = f'/data/students/mary/mlops-exercises/ME6/dataset/json_files/v1_instances_val.json'\n",
    "with open(filename, 'w') as file:\n",
    "    json.dump(v1_data, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge JSON Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_v1 = \"/data/students/mary/mlops-exercises/ME6/dataset__v3/v1_instances_train.json\"\n",
    "file_v3 = \"/data/students/mary/mlops-exercises/ME6/dataset__v3/adj01_instances_train.json\"\n",
    "\n",
    "# Load the second JSON file\n",
    "with open(file_v1, 'r') as f1:\n",
    "    v1_data = json.load(f1)\n",
    "\n",
    "# Load the first JSON file\n",
    "with open(file_v3, 'r') as f3:\n",
    "    v3_data = json.load(f3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the 'images' lists\n",
    "merged_data = {\n",
    "    'images': v1_data['images'] + v3_data['images'],\n",
    "    'categories': v3_data['categories'],\n",
    "    'annotations': v1_data['annotations'] + v3_data['annotations'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON files merged successfully.\n"
     ]
    }
   ],
   "source": [
    "filename = f'/data/students/mary/mlops-exercises/ME6/dataset__v3/merged_instances_train.json'\n",
    "\n",
    "# Save the merged result to a new JSON file\n",
    "with open(filename, 'w') as f:\n",
    "    json.dump(merged_data, f, indent=4)\n",
    "\n",
    "print(\"JSON files merged successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_v1 = \"/data/students/mary/mlops-exercises/ME6/dataset__v3/v1_instances_val.json\"\n",
    "file_v3 = \"/data/students/mary/mlops-exercises/ME6/dataset__v3/adj01_instances_val.json\"\n",
    "\n",
    "# Load the second JSON file\n",
    "with open(file_v1, 'r') as f1:\n",
    "    v1_data = json.load(f1)\n",
    "\n",
    "# Load the first JSON file\n",
    "with open(file_v3, 'r') as f3:\n",
    "    v3_data = json.load(f3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the 'images' lists\n",
    "merged_data = {\n",
    "    'images': v1_data['images'] + v3_data['images'],\n",
    "    'categories': v3_data['categories'],\n",
    "    'annotations': v1_data['annotations'] + v3_data['annotations'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON files merged successfully.\n"
     ]
    }
   ],
   "source": [
    "filename = f'/data/students/mary/mlops-exercises/ME6/dataset__v3/merged_instances_val.json'\n",
    "\n",
    "# Save the merged result to a new JSON file\n",
    "with open(filename, 'w') as f:\n",
    "    json.dump(merged_data, f, indent=4)\n",
    "\n",
    "print(\"JSON files merged successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI231_ME6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
