{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Number of GPUs: 1\n",
      "GPU name: NVIDIA A100-SXM4-40GB\n",
      "PyTorch version: 2.5.1+cu121\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "# Setting up the environment to use only GPU 2\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Check number of GPUs\n",
    "print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "\n",
    "# Check GPU name\n",
    "print(f\"GPU name: {torch.cuda.get_device_name()}\")\n",
    "\n",
    "# Check PyTorch version\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /data/students/mary/anaconda3/envs/AI231_ME6/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Fri Dec  6 16:15:22 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.154.05             Driver Version: 535.154.05   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A100-SXM4-40GB          On  | 00000000:07:00.0 Off |                    0 |\n",
      "| N/A   49C    P0             328W / 400W |  34420MiB / 40960MiB |     97%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100-SXM4-40GB          On  | 00000000:0F:00.0 Off |                    0 |\n",
      "| N/A   23C    P0              60W / 400W |  10350MiB / 40960MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA A100-SXM4-40GB          On  | 00000000:47:00.0 Off |                    0 |\n",
      "| N/A   40C    P0             203W / 400W |  21670MiB / 40960MiB |     72%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA A100-SXM4-40GB          On  | 00000000:4E:00.0 Off |                    0 |\n",
      "| N/A   29C    P0             247W / 400W |  12676MiB / 40960MiB |     44%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA A100-SXM4-40GB          On  | 00000000:87:00.0 Off |                    0 |\n",
      "| N/A   47C    P0              68W / 400W |  29704MiB / 40960MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA A100-SXM4-40GB          On  | 00000000:90:00.0 Off |                    0 |\n",
      "| N/A   37C    P0              86W / 400W |  31648MiB / 40960MiB |     61%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   6  NVIDIA A100-SXM4-40GB          On  | 00000000:B7:00.0 Off |                    0 |\n",
      "| N/A   32C    P0              62W / 400W |   9714MiB / 40960MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   7  NVIDIA A100-SXM4-40GB          On  | 00000000:BD:00.0 Off |                    0 |\n",
      "| N/A   27C    P0              60W / 400W |   8528MiB / 40960MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A     89563      C   ...eph/anaconda3/envs/myenv/bin/python      638MiB |\n",
      "|    0   N/A  N/A    276105      C   python                                    12770MiB |\n",
      "|    0   N/A  N/A    633372      C   ...hel/anaconda3/envs/AI321/bin/python      514MiB |\n",
      "|    0   N/A  N/A    815739      C   ...hel/anaconda3/envs/AI321/bin/python      514MiB |\n",
      "|    0   N/A  N/A    997150      C   python                                    18578MiB |\n",
      "|    0   N/A  N/A   3782067      C   ...eph/anaconda3/envs/myenv/bin/python      620MiB |\n",
      "|    1   N/A  N/A   1802788      C   ...naconda3/envs/mex4_orion/bin/python     5330MiB |\n",
      "|    2   N/A  N/A   1501171      C   ...line/anaconda3/envs/BFCL/bin/python    16704MiB |\n",
      "|    3   N/A  N/A   1363169      C   python                                    12078MiB |\n",
      "|    4   N/A  N/A    604612      C   ...naconda3/envs/ai231-venv/bin/python     6260MiB |\n",
      "|    4   N/A  N/A   1054301      C   ...naconda3/envs/ai231-venv/bin/python    23388MiB |\n",
      "|    5   N/A  N/A   1489065      C   ...conda3/envs/bertram_mex5/bin/python    31586MiB |\n",
      "|    6   N/A  N/A   1533795      C   ...anaconda3/envs/class_env/bin/python     9416MiB |\n",
      "|    7   N/A  N/A     89563      C   ...eph/anaconda3/envs/myenv/bin/python     3036MiB |\n",
      "|    7   N/A  N/A   3782067      C   ...eph/anaconda3/envs/myenv/bin/python     3130MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PosixPath('/data/students/mary/mlops-exercises/ME6/dataset__all/train/labels'), PosixPath('/data/students/mary/mlops-exercises/ME6/dataset__all/val/labels')]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "dataset_path = Path(\"/data/students/mary/mlops-exercises/ME6/dataset__all\")  # replace with 'path/to/dataset' for your custom data\n",
    "labels = sorted(dataset_path.rglob(\"*labels/*.txt\"))  # all data in 'labels'\n",
    "print(sorted(dataset_path.rglob(\"*labels\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "yaml_file = \"dataset.yaml\" \n",
    "with open(yaml_file, \"r\", encoding=\"utf8\") as y:\n",
    "    data = yaml.safe_load(y)\n",
    "\n",
    "names = data['names']\n",
    "class_dict = {i: name for i, name in enumerate(names)}\n",
    "cls_idx = sorted(class_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "indx = [label.stem for label in labels]  # uses base filename as ID (no extension)\n",
    "labels_df = pd.DataFrame([], columns=cls_idx, index=indx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1555352/4074969495.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  labels_df = labels_df.fillna(0.0)  # replace `nan` values with `0.0`\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "for label in labels:\n",
    "    lbl_counter = Counter()\n",
    "\n",
    "    with open(label, \"r\") as lf:\n",
    "        lines = lf.readlines()\n",
    "\n",
    "    for line in lines:\n",
    "        # classes for YOLO label uses integer at first position of each line\n",
    "        lbl_counter[int(line.split(\" \")[0])] += 1\n",
    "\n",
    "    labels_df.loc[label.stem] = lbl_counter\n",
    "\n",
    "labels_df = labels_df.fillna(0.0)  # replace `nan` values with `0.0`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KFold Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "ksplit = 3\n",
    "kf = KFold(n_splits=ksplit, shuffle=True, random_state=20)  # setting random_state for repeatable results\n",
    "\n",
    "kfolds = list(kf.split(labels_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1555352/1666497045.py:5: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  folds_df[f\"split_{idx}\"].loc[labels_df.iloc[train].index] = \"train\"\n",
      "/tmp/ipykernel_1555352/1666497045.py:6: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  folds_df[f\"split_{idx}\"].loc[labels_df.iloc[val].index] = \"val\"\n"
     ]
    }
   ],
   "source": [
    "folds = [f\"split_{n}\" for n in range(1, ksplit + 1)]\n",
    "folds_df = pd.DataFrame(index=indx, columns=folds)\n",
    "\n",
    "for idx, (train, val) in enumerate(kfolds, start=1):\n",
    "    folds_df[f\"split_{idx}\"].loc[labels_df.iloc[train].index] = \"train\"\n",
    "    folds_df[f\"split_{idx}\"].loc[labels_df.iloc[val].index] = \"val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_lbl_distrb = pd.DataFrame(index=folds, columns=cls_idx)\n",
    "\n",
    "for n, (train_indices, val_indices) in enumerate(kfolds, start=1):\n",
    "    train_totals = labels_df.iloc[train_indices].sum()\n",
    "    val_totals = labels_df.iloc[val_indices].sum()\n",
    "\n",
    "    # To avoid division by zero, we add a small value (1E-7) to the denominator\n",
    "    ratio = val_totals / (train_totals + 1e-7)\n",
    "    fold_lbl_distrb.loc[f\"split_{n}\"] = ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "supported_extensions = [\".jpg\", \".jpeg\", \".png\"]\n",
    "\n",
    "# Initialize an empty list to store image file paths\n",
    "images = []\n",
    "\n",
    "# Loop through supported extensions and gather image files\n",
    "for ext in supported_extensions:\n",
    "    images.extend(sorted((dataset_path / \"train/images\").rglob(f\"*{ext}\")))\n",
    "    images.extend(sorted((dataset_path / \"val/images\").rglob(f\"*{ext}\")))\n",
    "# Create the necessary directories and dataset YAML files (unchanged)\n",
    "save_path = Path(dataset_path / f\"{datetime.date.today().isoformat()}_{ksplit}-Fold_Cross-val\")\n",
    "save_path.mkdir(parents=True, exist_ok=True)\n",
    "ds_yamls = []\n",
    "\n",
    "for split in folds_df.columns:\n",
    "    # Create directories\n",
    "    split_dir = save_path / split\n",
    "    split_dir.mkdir(parents=True, exist_ok=True)\n",
    "    (split_dir / \"train\" / \"images\").mkdir(parents=True, exist_ok=True)\n",
    "    (split_dir / \"train\" / \"labels\").mkdir(parents=True, exist_ok=True)\n",
    "    (split_dir / \"val\" / \"images\").mkdir(parents=True, exist_ok=True)\n",
    "    (split_dir / \"val\" / \"labels\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Create dataset YAML files\n",
    "    dataset_yaml = split_dir / f\"{split}_dataset.yaml\"\n",
    "    ds_yamls.append(dataset_yaml)\n",
    "\n",
    "    with open(dataset_yaml, \"w\") as ds_y:\n",
    "        yaml.safe_dump(\n",
    "            {\n",
    "                \"path\": split_dir.as_posix(),\n",
    "                \"train\": \"train\",\n",
    "                \"val\": \"val\",\n",
    "                \"names\": names,\n",
    "            },\n",
    "            ds_y,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 040488 not found in folds_df index\n",
      "Warning: 090474 not found in folds_df index\n",
      "Warning: 240461 not found in folds_df index\n",
      "Warning: 020314 not found in folds_df index\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "for image, label in zip(images, labels):\n",
    "    image_stem = image.stem\n",
    "    if image_stem in folds_df.index:\n",
    "        for split, k_split in folds_df.loc[image_stem].items():\n",
    "            # Destination directory\n",
    "            img_to_path = save_path / split / k_split / \"images\"\n",
    "            lbl_to_path = save_path / split / k_split / \"labels\"\n",
    "            img_to_path.mkdir(parents=True, exist_ok=True)\n",
    "            lbl_to_path.mkdir(parents=True, exist_ok=True)\n",
    "            shutil.copy(image, img_to_path / image.name)\n",
    "            shutil.copy(label, lbl_to_path / f\"{image_stem}.txt\")\n",
    "    else:\n",
    "        print(f\"Warning: {image_stem} not found in folds_df index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds_df.to_csv(save_path / \"kfold_datasplit.csv\")\n",
    "fold_lbl_distrb.to_csv(save_path / \"kfold_label_distribution.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training with Kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import comet_ml\n",
    "\n",
    "comet_ml.login(project_name=\"MEX6_runners\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11s-seg.pt to 'yolo11s-seg.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19.7M/19.7M [00:00<00:00, 55.9MB/s]\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"yolo11s-seg.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.43 🚀 Python-3.11.10 torch-2.5.1+cu121 CUDA:0 (NVIDIA A100-SXM4-40GB, 40339MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=yolo11s-seg.pt, data=/data/students/mary/mlops-exercises/ME6/dataset__all/2024-12-06_3-Fold_Cross-val/split_1/split_1_dataset.yaml, epochs=150, time=None, patience=5, batch=32, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=MEX6_runners, name=runkfold01, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=MEX6_runners/runkfold01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/students/mary/anaconda3/envs/AI231_ME6/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-12-06 16:18:52,363\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2024-12-06 16:18:52,450\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml nc=80 with nc=24\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n",
      "  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  6                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    443776  ultralytics.nn.modules.block.C3k2            [768, 256, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    127680  ultralytics.nn.modules.block.C3k2            [512, 128, 1, False]          \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    345472  ultralytics.nn.modules.block.C3k2            [384, 256, 1, False]          \n",
      " 20                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n",
      " 23        [16, 19, 22]  1   1483192  ultralytics.nn.modules.head.Segment          [24, 32, 128, [128, 256, 512]]\n",
      "YOLO11s-seg summary: 355 layers, 10,091,576 parameters, 10,091,560 gradients, 35.6 GFLOPs\n",
      "\n",
      "Transferred 555/561 items from pretrained weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: sklearn, torch.\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/marynathalie/mex6-runners/fadb41dfde9c4fadb712c9463dfeff5d\n",
      "\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Couldn't find a Git repository in '/raid/students/mary/mlops-exercises/ME6/model_dev' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir MEX6_runners/runkfold01', view at http://localhost:6006/\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /raid/students/mary/mlops-exercises/ME6/dataset__all/2024-12-06_3-Fold_Cross-val/split_1/train/labels... 7450 images, 0 backgrounds, 0 corrupt: 100%|██████████| 7450/7450 [00:04<00:00, 1743.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /raid/students/mary/mlops-exercises/ME6/dataset__all/2024-12-06_3-Fold_Cross-val/split_1/train/images/040399.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /raid/students/mary/mlops-exercises/ME6/dataset__all/2024-12-06_3-Fold_Cross-val/split_1/train/images/240460.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /raid/students/mary/mlops-exercises/ME6/dataset__all/2024-12-06_3-Fold_Cross-val/split_1/train/images/250003.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /raid/students/mary/mlops-exercises/ME6/dataset__all/2024-12-06_3-Fold_Cross-val/split_1/train/images/250009.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /raid/students/mary/mlops-exercises/ME6/dataset__all/2024-12-06_3-Fold_Cross-val/split_1/train/images/250010.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /raid/students/mary/mlops-exercises/ME6/dataset__all/2024-12-06_3-Fold_Cross-val/split_1/train/images/250105.jpg: 1 duplicate labels removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /raid/students/mary/mlops-exercises/ME6/dataset__all/2024-12-06_3-Fold_Cross-val/split_1/train/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /raid/students/mary/mlops-exercises/ME6/dataset__all/2024-12-06_3-Fold_Cross-val/split_1/val/labels... 3725 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3725/3725 [00:02<00:00, 1302.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /raid/students/mary/mlops-exercises/ME6/dataset__all/2024-12-06_3-Fold_Cross-val/split_1/val/images/040333.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /raid/students/mary/mlops-exercises/ME6/dataset__all/2024-12-06_3-Fold_Cross-val/split_1/val/images/250038.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /raid/students/mary/mlops-exercises/ME6/dataset__all/2024-12-06_3-Fold_Cross-val/split_1/val/images/250044.jpg: 1 duplicate labels removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /raid/students/mary/mlops-exercises/ME6/dataset__all/2024-12-06_3-Fold_Cross-val/split_1/val/labels.cache\n",
      "Plotting labels to MEX6_runners/runkfold01/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 90 weight(decay=0.0), 101 weight(decay=0.0005), 100 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mMEX6_runners/runkfold01\u001b[0m\n",
      "Starting training for 150 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/150      10.6G      2.395      4.488      4.455      2.358        124        640: 100%|██████████| 233/233 [01:43<00:00,  2.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 59/59 [01:22<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3725       8476      0.346      0.151      0.114     0.0685      0.332      0.138      0.102      0.057\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      2/150      10.2G      2.315      4.035      3.383      2.222         99        640: 100%|██████████| 233/233 [03:47<00:00,  1.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 59/59 [01:10<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3725       8476       0.48      0.142      0.124     0.0725      0.438      0.132       0.11     0.0649\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      3/150      10.2G      2.334       4.13      3.455      2.281        118        640: 100%|██████████| 233/233 [02:14<00:00,  1.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 59/59 [01:43<00:00,  1.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3725       8476      0.435     0.0641     0.0359     0.0172      0.472     0.0526     0.0308     0.0128\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      4/150      10.3G      2.433      4.231      3.709      2.388        118        640: 100%|██████████| 233/233 [02:32<00:00,  1.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95):  86%|████████▋ | 51/59 [01:33<00:14,  1.83s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m     dataset_yaml \u001b[38;5;241m=\u001b[39m ds_yamls[k]\n\u001b[1;32m     14\u001b[0m     model \u001b[38;5;241m=\u001b[39m YOLO(weights_path)\n\u001b[0;32m---> 15\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain(\n\u001b[1;32m     16\u001b[0m         data\u001b[38;5;241m=\u001b[39mdataset_yaml,\n\u001b[1;32m     17\u001b[0m         project\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMEX6_runners\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     18\u001b[0m         epochs\u001b[38;5;241m=\u001b[39mepochs,\n\u001b[1;32m     19\u001b[0m         imgsz\u001b[38;5;241m=\u001b[39mimgsz,\n\u001b[1;32m     20\u001b[0m         batch\u001b[38;5;241m=\u001b[39mbatch,\n\u001b[1;32m     21\u001b[0m         patience\u001b[38;5;241m=\u001b[39mpatience,\n\u001b[1;32m     22\u001b[0m         name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrunkfold0\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     23\u001b[0m     )\n\u001b[1;32m     24\u001b[0m     results[k] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mmetrics  \u001b[38;5;66;03m# save output metrics for further analysis\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Save results to a CSV file\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/AI231_ME6/lib/python3.11/site-packages/ultralytics/engine/model.py:805\u001b[0m, in \u001b[0;36mModel.train\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    802\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mhub_session \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession  \u001b[38;5;66;03m# attach optional HUB session\u001b[39;00m\n\u001b[0;32m--> 805\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m    806\u001b[0m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[1;32m    807\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m}:\n",
      "File \u001b[0;32m~/anaconda3/envs/AI231_ME6/lib/python3.11/site-packages/ultralytics/engine/trainer.py:207\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    204\u001b[0m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 207\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_train(world_size)\n",
      "File \u001b[0;32m~/anaconda3/envs/AI231_ME6/lib/python3.11/site-packages/ultralytics/engine/trainer.py:432\u001b[0m, in \u001b[0;36mBaseTrainer._do_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;66;03m# Validation\u001b[39;00m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mval \u001b[38;5;129;01mor\u001b[39;00m final_epoch \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstopper\u001b[38;5;241m.\u001b[39mpossible_stop \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop:\n\u001b[0;32m--> 432\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetrics, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfitness \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidate()\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_metrics(metrics\u001b[38;5;241m=\u001b[39m{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_loss_items(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtloss), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetrics, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr})\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstopper(epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfitness) \u001b[38;5;129;01mor\u001b[39;00m final_epoch\n",
      "File \u001b[0;32m~/anaconda3/envs/AI231_ME6/lib/python3.11/site-packages/ultralytics/engine/trainer.py:605\u001b[0m, in \u001b[0;36mBaseTrainer.validate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    600\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;124;03m    Runs validation on test set using self.validator.\u001b[39;00m\n\u001b[1;32m    602\u001b[0m \n\u001b[1;32m    603\u001b[0m \u001b[38;5;124;03m    The returned dict is expected to contain \"fitness\" key.\u001b[39;00m\n\u001b[1;32m    604\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidator(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    606\u001b[0m     fitness \u001b[38;5;241m=\u001b[39m metrics\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfitness\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())  \u001b[38;5;66;03m# use loss as fitness measure if not found\u001b[39;00m\n\u001b[1;32m    607\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_fitness \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_fitness \u001b[38;5;241m<\u001b[39m fitness:\n",
      "File \u001b[0;32m~/anaconda3/envs/AI231_ME6/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/AI231_ME6/lib/python3.11/site-packages/ultralytics/engine/validator.py:189\u001b[0m, in \u001b[0;36mBaseValidator.__call__\u001b[0;34m(self, trainer, model)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;66;03m# Postprocess\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m dt[\u001b[38;5;241m3\u001b[39m]:\n\u001b[0;32m--> 189\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess(preds)\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_metrics(preds, batch)\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mplots \u001b[38;5;129;01mand\u001b[39;00m batch_i \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m3\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/AI231_ME6/lib/python3.11/site-packages/ultralytics/models/yolo/segment/val.py:73\u001b[0m, in \u001b[0;36mSegmentationValidator.postprocess\u001b[0;34m(self, preds)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpostprocess\u001b[39m(\u001b[38;5;28mself\u001b[39m, preds):\n\u001b[1;32m     72\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Post-processes YOLO predictions and returns output detections with proto.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     p \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mnon_max_suppression(\n\u001b[1;32m     74\u001b[0m         preds[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m     75\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mconf,\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39miou,\n\u001b[1;32m     77\u001b[0m         labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlb,\n\u001b[1;32m     78\u001b[0m         multi_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     79\u001b[0m         agnostic\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39msingle_cls \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39magnostic_nms,\n\u001b[1;32m     80\u001b[0m         max_det\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mmax_det,\n\u001b[1;32m     81\u001b[0m         nc\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnc,\n\u001b[1;32m     82\u001b[0m     )\n\u001b[1;32m     83\u001b[0m     proto \u001b[38;5;241m=\u001b[39m preds[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(preds[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m preds[\u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# second output is len 3 if pt, but only 1 if exported\u001b[39;00m\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m p, proto\n",
      "File \u001b[0;32m~/anaconda3/envs/AI231_ME6/lib/python3.11/site-packages/ultralytics/utils/ops.py:291\u001b[0m, in \u001b[0;36mnon_max_suppression\u001b[0;34m(prediction, conf_thres, iou_thres, classes, agnostic, multi_label, labels, max_det, nc, max_time_img, max_nms, max_wh, in_place, rotated)\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    290\u001b[0m     boxes \u001b[38;5;241m=\u001b[39m x[:, :\u001b[38;5;241m4\u001b[39m] \u001b[38;5;241m+\u001b[39m c  \u001b[38;5;66;03m# boxes (offset by class)\u001b[39;00m\n\u001b[0;32m--> 291\u001b[0m     i \u001b[38;5;241m=\u001b[39m torchvision\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mnms(boxes, scores, iou_thres)  \u001b[38;5;66;03m# NMS\u001b[39;00m\n\u001b[1;32m    292\u001b[0m i \u001b[38;5;241m=\u001b[39m i[:max_det]  \u001b[38;5;66;03m# limit detections\u001b[39;00m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;66;03m# # Experimental\u001b[39;00m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;66;03m# merge = False  # use merge-NMS\u001b[39;00m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;66;03m# if merge and (1 < n < 3E3):  # Merge NMS (boxes merged using weighted mean)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;66;03m#     if redundant:\u001b[39;00m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;66;03m#         i = i[iou.sum(1) > 1]  # require redundancy\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/AI231_ME6/lib/python3.11/site-packages/torchvision/ops/boxes.py:41\u001b[0m, in \u001b[0;36mnms\u001b[0;34m(boxes, scores, iou_threshold)\u001b[0m\n\u001b[1;32m     39\u001b[0m     _log_api_usage_once(nms)\n\u001b[1;32m     40\u001b[0m _assert_has_ops()\n\u001b[0;32m---> 41\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mtorchvision\u001b[38;5;241m.\u001b[39mnms(boxes, scores, iou_threshold)\n",
      "File \u001b[0;32m~/anaconda3/envs/AI231_ME6/lib/python3.11/site-packages/torch/_ops.py:1116\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_torchbind_op_overload \u001b[38;5;129;01mand\u001b[39;00m _must_dispatch_in_python(args, kwargs):\n\u001b[1;32m   1115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _call_overload_packet_from_python(\u001b[38;5;28mself\u001b[39m, args, kwargs)\n\u001b[0;32m-> 1116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_op(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(kwargs \u001b[38;5;129;01mor\u001b[39;00m {}))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "weights_path = \"yolo11s-seg.pt\"\n",
    "\n",
    "batch = 32\n",
    "imgsz = 640\n",
    "patience = 5\n",
    "epochs = 150\n",
    "\n",
    "results = {}\n",
    "\n",
    "for k in range(ksplit):\n",
    "    dataset_yaml = ds_yamls[k]\n",
    "    model = YOLO(weights_path)\n",
    "    model.train(\n",
    "        data=dataset_yaml,\n",
    "        project=\"MEX6_runners\",\n",
    "        epochs=epochs,\n",
    "        imgsz=imgsz,\n",
    "        batch=batch,\n",
    "        patience=patience,\n",
    "        name=f\"runkfold0{k+1}\"\n",
    "    )\n",
    "    results[k] = model.metrics  # save output metrics for further analysis\n",
    "\n",
    "# Save results to a CSV file\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(save_path / \"kfold_results.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI231_ME6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
